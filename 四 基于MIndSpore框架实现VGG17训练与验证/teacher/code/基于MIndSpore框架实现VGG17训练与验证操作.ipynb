{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c053448-3650-4741-98bd-40e734010c8e",
   "metadata": {},
   "source": [
    "## 实验四：基于MindSpore框架实现VGG17训练与验证"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57762448",
   "metadata": {},
   "source": [
    "本实验基于Modelarts平台，使用MindSpore深度学习框架，利用其成熟的算子库搭建VGG17神经网络模型，使用花卉数据集（雏菊、蒲公英、玫瑰、向日葵、郁金香）在Ascend910加速卡上进行训练和验证。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e461c40-fd4d-4da4-aafe-0b6efa0b0edf",
   "metadata": {},
   "source": [
    "### 1. 实验目的\n",
    "* 熟悉和使用MindSpore框架和ModelArts，熟悉MindSpore常见API的使用方法，熟悉ModelArts一站式模型训练和部署平台。\n",
    "* 基于MindSpore框架构建VGG17网络。利用花卉数据集上完成模型训练（训练平台：ModelArts，可采用昇腾910芯片进行训练）。模型训练完成后，对模型进行保存。\n",
    "* 基于昇腾310推理芯片作为计算平台，利用MindSpore框架导入训练好的模型，并在花卉测试数据集对构建的模型进行推理验证，输出推理性能以及测试集正确率。\n",
    "* 本实验希望借助MindSpore帮助学生熟悉使用深度学习框架，感受框架封装基本操作的便捷。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b7bcf7",
   "metadata": {},
   "source": [
    "### 2. 背景介绍\n",
    "### 2.1 VGG模型原理介绍\n",
    "该模块简要介绍VGG网络的原理。\n",
    "- 在VGG中，使用了3个3x3卷积核来代替7x7卷积核，使用了2个3x3卷积核来代替5*5卷积核，相比AlexNet中的较大卷积核（11x11，7x7，5x5），VGG网络层数更深，提升了网络性能。\n",
    "- 池化层均采用相同的池化核参数，stride=2。\n",
    "- 模型由若干卷积层和池化层堆叠的方式构成。\n",
    "\n",
    "注：在构造网络时，还需要考虑BN(Batch Normalization)层和Relu层（BN层可以提高网络训练稳定性，Relu层是非线性激活层）。此外为了提高网络鲁棒性，加入了dropout层。\n",
    "\n",
    "VGG网络结构如下表所示："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377137d3",
   "metadata": {},
   "source": [
    "\n",
    "| 算子           | 类型     | 输入通道数 | 输出通道数 | 窗口大小 | 边界扩充大小 | 步长 | 输出张量的高度和宽度 |\n",
    "| -------------- | -------- | ---------- | ---------- | -------- | ------------ | ---- | -------------------- |\n",
    "| layer1_conv1   | 卷积     | 3          | 64         | 3        | 1            | 1    | 224x224              |\n",
    "| layer1_conv2   | 卷积     | 64         | 64         | 3        | 1            | 1    | 224x224              |\n",
    "| layer1_maxpool | 最大池化 | 64         | 64         | 2        | -            | 2    | 112x112              |\n",
    "| layer2_conv1   | 卷积     | 64         | 128        | 3        | 1            | 1    | 112x112              |\n",
    "| layer2_conv2   | 卷积     | 128        | 128        | 3        | 1            | 1    | 112x112              |\n",
    "| layer2_maxpool | 最大池化 | 128        | 128        | 2        | -            | 2    | 56x56                |\n",
    "| layer3_conv1   | 卷积     | 128        | 256        | 3        | 1            | 1    | 56x56                |\n",
    "| layer3_conv2   | 卷积     | 256        | 256        | 3        | 1            | 1    | 56x56                |\n",
    "| layer3_conv3   | 卷积     | 256        | 256        | 3        | 1            | 1    | 56x56                |\n",
    "| layer3_maxpool | 最大池化 | 256        | 256        | 2        | -            | 2    | 28x28                |\n",
    "| layer4_conv1   | 卷积     | 256        | 512        | 3        | 1            | 1    | 28x28                |\n",
    "| layer4_conv2   | 卷积     | 512        | 512        | 3        | 1            | 1    | 28x28                |\n",
    "| layer4_conv3   | 卷积     | 512        | 512        | 3        | 1            | 1    | 28x28                |\n",
    "| layer4_maxpool | 最大池化 | 512        | 512        | 2        | -            | 2    | 14x14                |\n",
    "| layer5_conv1   | 卷积     | 512        | 512        | 3        | 1            | 1    | 14x14                |\n",
    "| layer5_conv2   | 卷积     | 512        | 512        | 3        | 1            | 1    | 14x14                |\n",
    "| layer5_conv3   | 卷积     | 512        | 512        | 3        | 1            | 1    | 14x14                |\n",
    "| layer5_conv4   | 卷积     | 512        | 512        | 3        | 1            | 1    | 14x14                |\n",
    "| layer5_maxpool | 最大池化 | 512        | 512        | 2        | -            | 2    | 7x7                  |\n",
    "| flatten        | 扁平化   | -          | -          | -        | -            | -    | -                    |\n",
    "| fullyconnect1  | 全连接   | 25088      | 4096       | -        | -            | -    | -                    |\n",
    "| fullyconnect2  | 全连接   | 4096       | 4096       | -        | -            | -    | -                    |\n",
    "| fullyconnect3  | 全连接   | 4096       | 4          | -        | -            | -    | -                    |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6992057",
   "metadata": {},
   "source": [
    "<img src=\"structure.png\" style=\"margin: 0 auto;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791eb9db",
   "metadata": {},
   "source": [
    "### 3. 实验环境\n",
    "\n",
    "环境：支持GPU和Ascend环境 \\\n",
    "版本：MindSpore 2.0 & 编程语言：Python 3.7 \\\n",
    "    在动手进行实践之前，确保你已经正确安装了MindSpore。如果没有，可以通过MindSpore官网安装页面：https://www.mindspore.cn/install/ ，将MindSpore安装在你的电脑当中。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e268dac4-6d6f-454f-9876-28a0d222df7a",
   "metadata": {},
   "source": [
    "### 4. 数据处理\n",
    "### 4.1 数据准备\n",
    "\n",
    "我们示例中用到的图像花卉数据集，总共包括5种花的类型：分别是daisy（雏菊，633张），dandelion（蒲公英，898张），roses（玫瑰，641张），sunflowers（向日葵，699张），tulips（郁金香，799张），保存在5个文件夹当中，总共3670张，大小大概在230M左右。为了在模型部署上线之后进行测试，数据集在这里分成了 flower_photos_train 和 flower_photos_test 两部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0373013",
   "metadata": {},
   "source": [
    "请点击数据集链接，下载以下数据集，下载的data.zip保存到code文件夹下，即和notebook同步目录"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e060cc5c",
   "metadata": {},
   "source": [
    "数据集链接：https://openi.pcl.ac.cn/attachments/88c31019-22cc-41ed-a31c-8f7b11435b60?type=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8be9634f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "def download_dataset(download_file, target_path):\n",
    "    if os.path.exists(target_path+\"data\"):\n",
    "        print(\"already exists\")\n",
    "        return\n",
    "        \n",
    "    if download_file.endswith(\"zip\"):\n",
    "        z = zipfile.ZipFile(download_file, \"r\")\n",
    "        z.extractall(path=target_path)\n",
    "        z.close()\n",
    "download_dataset(\"data.zip\",\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e45b037",
   "metadata": {},
   "source": [
    "在code的同级目录下，data文件夹的结构如下：\\\n",
    "./code \\\n",
    "|── train.py \\\n",
    "./data \\\n",
    "|&emsp;&emsp;&emsp;|── train \\\n",
    "|&emsp;&emsp;&emsp;|&emsp;&emsp;&emsp;|── daisy \\\n",
    "|&emsp;&emsp;&emsp;|&emsp;&emsp;&emsp;|── dandelion \\\n",
    "|&emsp;&emsp;&emsp;|&emsp;&emsp;&emsp;|── roses \\\n",
    "|&emsp;&emsp;&emsp;|&emsp;&emsp;&emsp;|── sunflowers \\\n",
    "|&emsp;&emsp;&emsp;|&emsp;&emsp;&emsp;|── tulips \\\n",
    "|&emsp;&emsp;&emsp;|── test \\\n",
    "|&emsp;&emsp;&emsp;|&emsp;&emsp;&emsp;|── daisy \\\n",
    "|&emsp;&emsp;&emsp;|&emsp;&emsp;&emsp;|── dandelion \\\n",
    "|&emsp;&emsp;&emsp;|&emsp;&emsp;&emsp;|── roses \\\n",
    "|&emsp;&emsp;&emsp;|&emsp;&emsp;&emsp;|── sunflowers \\\n",
    "|&emsp;&emsp;&emsp;|&emsp;&emsp;&emsp;|── tulips \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd293613",
   "metadata": {},
   "source": [
    "\n",
    "### 4.2 数据加载\n",
    "在得到数据集后，利用mindspore.dataset类下的ImageFolder Dataset加载图片数据，同一个文件夹中的所有图片将被分配相同的label。并使用Random Crop，RandomHorizontalFlip，HWC2CHW和Resize几种的数据增强操作。模块实现如下：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1daf8be6-da88-490c-bc00-f288444d1a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_create_dataset(data_home, image_size, batch_size, rank_id=0, rank_size=1, training=True):\n",
    "    #加载路径\n",
    "    \"\"\"Data operations.\"\"\"\n",
    "    if training:\n",
    "        data_dir = os.path.join(data_home, \"train\")\n",
    "    else:\n",
    "        data_dir = os.path.join(data_home, \"test\")\n",
    "        print(\"data_dir\",data_dir)\n",
    "    data_set = de.ImageFolderDataset(data_dir,\n",
    "                                     class_indexing={'daisy':0,'dandelion':1,'roses':2,'sunflowers':3,'tulips':4},\n",
    "                                     shuffle=False, num_shards=rank_size, shard_id=rank_id)\n",
    "\n",
    "    #数据增强的方法，上述提高的四种方法\n",
    "    transform_img = vision.RandomCropDecodeResize([224,224], scale=(0.08, 1.0),\n",
    "                                              ratio=(0.75, 1.333))  # 改变尺寸\n",
    "\n",
    "    changeswap_op = vision.HWC2CHW()\n",
    "    type_cast_op = C.TypeCast(mstype.float32)\n",
    "    random_horizontal_op = vision.RandomHorizontalFlip()\n",
    "    #normalize_op =  vision.Normalize((0.4465, 0.4822, 0.4914), (0.2010, 0.1994, 0.2023))\n",
    "\n",
    "    #map操作将指定函数操作于数据集的指定列数据\n",
    "    data_set = data_set.map(input_columns=\"image\", operations=transform_img)\n",
    "    data_set = data_set.map(input_columns=\"image\", operations=type_cast_op)\n",
    "    data_set = data_set.map(input_columns=\"image\", operations=random_horizontal_op)\n",
    "    data_set = data_set.map(input_columns=\"image\", operations=changeswap_op)\n",
    "\n",
    "    # shuffle来进行数据集的混洗\n",
    "    data_set = data_set.shuffle(buffer_size=data_set.get_dataset_size())\n",
    "\n",
    "    # 连续 batch_size 条数据合并为一个批处理数据\n",
    "    data_set = data_set.batch(batch_size=batch_size, drop_remainder=True)\n",
    "    return data_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d08d9e-a33f-4710-b1bc-7b954331631c",
   "metadata": {},
   "source": [
    "### 5. 实验内容"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f9c4e4-6027-49d1-a187-7d8a8e5551bf",
   "metadata": {},
   "source": [
    "本模块需要利用MindSpore.nn相关API完整搭建VGG17网络结构。在利用MindSpore构建网络时，需要继承 mindspore.nn.Cell 类，并重写 \\__init\\__ 方法和construct方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1a4f489-b40f-418b-9f57-c95267e07e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.nn as nn\n",
    "\n",
    "\n",
    "class Vgg(nn.Cell):\n",
    "    \"\"\"\n",
    "    VGG网络定义.\n",
    "\n",
    "    参数:\n",
    "        num_classes (int): Class numbers. Default: 5.\n",
    "        phase (int): 指定是训练/评估阶段\n",
    "\n",
    "    返回值:\n",
    "        Tensor, infer output tensor.\n",
    "        \n",
    "    example：\n",
    "        self.layer1_conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3,weight_init='XavierUniform')\n",
    "        self.layer1_bn1 = nn.BatchNorm2d(num_features=64)\n",
    "        self.layer1_relu1 = nn.LeakyReLU()\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=5, args=None, phase=\"train\"):\n",
    "        super(Vgg, self).__init__()\n",
    "        dropout_ratio = 0.5\n",
    "        if not args.has_dropout or phase == \"test\":\n",
    "            dropout_ratio = 1.0\n",
    "        \n",
    "        self.layer1_conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3,weight_init='XavierUniform')\n",
    "        self.layer1_bn1 = nn.BatchNorm2d(num_features=64)\n",
    "        self.layer1_relu1 = nn.ReLU()\n",
    "        self.layer1_conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3,weight_init='XavierUniform')\n",
    "        self.layer1_bn2 = nn.BatchNorm2d(num_features=64)\n",
    "        self.layer1_relu2 = nn.ReLU()\n",
    "        self.layer1_maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.layer2_conv1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3,weight_init='XavierUniform')\n",
    "        self.layer2_bn1 = nn.BatchNorm2d(num_features=128)\n",
    "        self.layer2_relu1 = nn.ReLU()\n",
    "        self.layer2_conv2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3,weight_init='XavierUniform')\n",
    "        self.layer2_bn2 = nn.BatchNorm2d(num_features=128)\n",
    "        self.layer2_relu2 = nn.ReLU()\n",
    "        self.layer2_maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.layer3_conv1 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3,weight_init='XavierUniform')\n",
    "        self.layer3_bn1 = nn.BatchNorm2d(num_features=256)\n",
    "        self.layer3_relu1 = nn.ReLU()\n",
    "        self.layer3_conv2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3,weight_init='XavierUniform')\n",
    "        self.layer3_bn2 = nn.BatchNorm2d(num_features=256)\n",
    "        self.layer3_relu2 = nn.ReLU()\n",
    "        self.layer3_conv3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3,weight_init='XavierUniform')\n",
    "        self.layer3_bn3 = nn.BatchNorm2d(num_features=256)\n",
    "        self.layer3_relu3 = nn.ReLU()\n",
    "        self.layer3_maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.layer4_conv1 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3,weight_init='XavierUniform')\n",
    "        self.layer4_bn1 = nn.BatchNorm2d(num_features=512)\n",
    "        self.layer4_relu1 = nn.ReLU()\n",
    "        self.layer4_conv2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3,weight_init='XavierUniform')\n",
    "        self.layer4_bn2 = nn.BatchNorm2d(num_features=512)\n",
    "        self.layer4_relu2 = nn.ReLU()\n",
    "        self.layer4_conv3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3,weight_init='XavierUniform')\n",
    "        self.layer4_bn3 = nn.BatchNorm2d(num_features=512)\n",
    "        self.layer4_relu3 = nn.ReLU()\n",
    "        self.layer4_maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.layer5_conv1 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3,weight_init='XavierUniform')\n",
    "        self.layer5_bn1 = nn.BatchNorm2d(num_features=512)\n",
    "        self.layer5_relu1 = nn.ReLU()\n",
    "        self.layer5_conv2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3,weight_init='XavierUniform')\n",
    "        self.layer5_bn2 = nn.BatchNorm2d(num_features=512)\n",
    "        self.layer5_relu2 = nn.ReLU()\n",
    "        self.layer5_conv3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3,weight_init='XavierUniform')\n",
    "        self.layer5_bn3 = nn.BatchNorm2d(num_features=512)\n",
    "        self.layer5_relu3 = nn.ReLU()\n",
    "        self.layer5_conv4 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3,weight_init='XavierUniform')\n",
    "        self.layer5_bn4 = nn.BatchNorm2d(num_features=512)\n",
    "        self.layer5_relu4 = nn.ReLU()\n",
    "        self.layer5_maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fullyconnect1 = nn.Dense(512 * 7 * 7, 4096)\n",
    "        self.relu_1 = nn.ReLU()\n",
    "        self.dropout_1 = nn.Dropout(dropout_ratio)\n",
    "\n",
    "        self.fullyconnect2 = nn.Dense(4096, 4096)\n",
    "        self.relu_2 = nn.ReLU()\n",
    "        self.dropout_1 = nn.Dropout(dropout_ratio)\n",
    "\n",
    "        self.fullyconnect3 = nn.Dense(4096, num_classes)\n",
    "\n",
    "\n",
    "    def construct(self, x):\n",
    "        x  =  self.layer1_conv1(x) \n",
    "        x  =  self.layer1_bn1(x)\n",
    "        x  =  self.layer1_relu1(x) \n",
    "        x  =  self.layer1_conv2(x)\n",
    "        x  =  self.layer1_bn2(x)\n",
    "        x  =  self.layer1_relu2(x) \n",
    "        x  =  self.layer1_maxpool(x)\n",
    "\n",
    "        x  =  self.layer2_conv1(x)\n",
    "        x  =  self.layer2_bn1(x) \n",
    "        x  =  self.layer2_relu1(x) \n",
    "        x  =  self.layer2_conv2(x)\n",
    "        x  =  self.layer2_bn2(x) \n",
    "        x  =  self.layer2_relu2(x) \n",
    "        x  =  self.layer2_maxpool(x)\n",
    "\n",
    "        x  =  self.layer3_conv1(x)\n",
    "        x  =  self.layer3_bn1(x) \n",
    "        x  =  self.layer3_relu1(x) \n",
    "        x  =  self.layer3_conv2(x)\n",
    "        x  =  self.layer3_bn2(x) \n",
    "        x  =  self.layer3_relu2(x) \n",
    "        x  =  self.layer3_conv3(x)\n",
    "        x  =  self.layer3_bn3(x) \n",
    "        x  =  self.layer3_relu3(x) \n",
    "        x  =  self.layer3_maxpool(x)\n",
    "\n",
    "        x  =  self.layer4_conv1(x)\n",
    "        x  =  self.layer4_bn1(x) \n",
    "        x  =  self.layer4_relu1(x) \n",
    "        x  =  self.layer4_conv2(x)\n",
    "        x  =  self.layer4_bn2(x) \n",
    "        x  =  self.layer4_relu2(x) \n",
    "        x  =  self.layer4_conv3(x)\n",
    "        x  =  self.layer4_bn3(x)\n",
    "        x  =  self.layer4_relu3(x) \n",
    "        x  =  self.layer4_maxpool(x)\n",
    "        \n",
    "        x  =  self.layer5_conv1(x)\n",
    "        x  =  self.layer5_bn1(x) \n",
    "        x  =  self.layer5_relu1(x) \n",
    "        x  =  self.layer5_conv2(x)\n",
    "        x  =  self.layer5_bn2(x) \n",
    "        x  =  self.layer5_relu2(x) \n",
    "        x  =  self.layer5_conv3(x)\n",
    "        x  =  self.layer5_bn3(x) \n",
    "        x  =  self.layer5_relu3(x) \n",
    "        x  =  self.layer5_conv4(x)\n",
    "        x  =  self.layer5_bn4(x) \n",
    "        x  =  self.layer5_relu4(x) \n",
    "        x  =  self.layer5_maxpool(x)\n",
    "\n",
    "        x = self.flatten(x) \n",
    "        x = self.fullyconnect1(x) \n",
    "        x = self.relu_1(x)\n",
    "        x = self.dropout_1(x) \n",
    "        x = self.fullyconnect2(x)\n",
    "        x = self.relu_2(x) \n",
    "        x = self.dropout_1(x) \n",
    "        x = self.fullyconnect3(x) \n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bbc4fa-90b4-4b0e-9a0a-b5534459a280",
   "metadata": {},
   "source": [
    "### 6. 模型构建\n",
    "\n",
    "实现模型训练的run_train()函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bbef117-0710-4cc0-bbbf-0b56f65d88de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config_path='/home/ma-user/work/exp4/teacher/code/flowerphotos_config.yaml')\n",
      "{'device_target': 'device where the code will be implemented.', 'dataset': 'flower_photos', 'data_dir': 'data dir', 'pre_trained': 'model_path, local pretrained model to load', 'lr_gamma': 'decrease lr by a factor of exponential lr_scheduler', 'eta_min': 'eta_min in cosine_annealing scheduler', 'T_max': 'T-max in cosine_annealing scheduler', 'log_interval': 'logging interval', 'ckpt_path': 'checkpoint save location', 'ckpt_interval': 'ckpt_interval', 'is_save_on_master': 'save ckpt on master or all rank', 'is_distributed': 'if multi device', 'per_batch_size': 'batch size for per npu', 'graph_ckpt': 'graph ckpt or feed ckpt', 'log_path': 'path to save log', 'result_dir': 'result files path.', 'label_dir': 'image file path.', 'dataset_name': 'flower_photos', 'result_path': 'result path', 'ckpt_file': 'vgg17 ckpt file.', 'file_name': 'vgg17 output file name.', 'file_format': \"file format, choices in ['AIR', 'ONNX', 'MINDIR']\"}\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2020 Huawei Technologies Co., Ltd\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "#################train vgg17 example on flowerphotos########################\n",
    "\"\"\"\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy\n",
    "import mindspore\n",
    "import mindspore.nn as nn\n",
    "from mindspore import Tensor\n",
    "from mindspore import context\n",
    "from mindspore.communication.management import init, get_rank, get_group_size\n",
    "from mindspore.nn import Momentum\n",
    "from mindspore.train import Accuracy\n",
    "from mindspore.train import ModelCheckpoint, CheckpointConfig, LossMonitor, TimeMonitor,Callback\n",
    "from mindspore.train import Model\n",
    "from mindspore import ParallelMode\n",
    "from mindspore import load_param_into_net, load_checkpoint\n",
    "from mindspore.amp import FixedLossScaleManager\n",
    "from mindspore import set_seed\n",
    "from src.dataset import vgg_create_dataset\n",
    "from src.dataset import classification_dataset\n",
    "\n",
    "from src.crossentropy import CrossEntropy\n",
    "from src.warmup_step_lr import warmup_step_lr\n",
    "from src.warmup_cosine_annealing_lr import warmup_cosine_annealing_lr\n",
    "from src.warmup_step_lr import lr_steps\n",
    "from src.utils.logging import get_logger\n",
    "from src.utils.util import get_param_groups\n",
    "from src.vgg import vgg17\n",
    "\n",
    "from model_utils.moxing_adapter import config\n",
    "from model_utils.moxing_adapter import moxing_wrapper\n",
    "from model_utils.device_adapter import get_device_id, get_rank_id, get_device_num\n",
    "\n",
    "import sys\n",
    "f = open('train.log', 'w')\n",
    "sys.stdout = f\n",
    "sys.stderr = f  \n",
    "\n",
    "#modelarts预处理部分\n",
    "def modelarts_pre_process():\n",
    "    sum=1\n",
    "    '''modelarts pre process function.'''\n",
    "    def unzip(zip_file, save_dir):\n",
    "        import zipfile\n",
    "        s_time = time.time()\n",
    "        if not os.path.exists(os.path.join(save_dir, config.modelarts_dataset_unzip_name)):\n",
    "            zip_isexist = zipfile.is_zipfile(zip_file)\n",
    "            if zip_isexist:\n",
    "                fz = zipfile.ZipFile(zip_file, 'r')\n",
    "                data_num = len(fz.namelist())\n",
    "                print(\"Extract Start...\")\n",
    "                print(\"unzip file num: {}\".format(data_num))\n",
    "                data_print = int(data_num / 100) if data_num > 100 else 1\n",
    "                i = 0\n",
    "                for file in fz.namelist():\n",
    "                    if i % data_print == 0:\n",
    "                        print(\"unzip percent: {}%\".format(int(i * 100 / data_num)), flush=True)\n",
    "                    i += 1\n",
    "                    fz.extract(file, save_dir)\n",
    "                print(\"cost time: {}min:{}s.\".format(int((time.time() - s_time) / 60),\n",
    "                                                     int(int(time.time() - s_time) % 60)))\n",
    "                print(\"Extract Done.\")\n",
    "            else:\n",
    "                print(\"This is not zip.\")\n",
    "        else:\n",
    "            print(\"Zip has been extracted.\")\n",
    "\n",
    "    if config.need_modelarts_dataset_unzip:\n",
    "        zip_file_1 = os.path.join(config.data_path, config.modelarts_dataset_unzip_name + \".zip\")\n",
    "        save_dir_1 = os.path.join(config.data_path)\n",
    "\n",
    "        sync_lock = \"/tmp/unzip_sync.lock\"\n",
    "\n",
    "        # Each server contains 8 devices as most.\n",
    "        if config.device_target == \"GPU\":\n",
    "            init()\n",
    "            device_id = get_rank()\n",
    "            device_num = get_group_size()\n",
    "        elif config.device_target == \"Ascend\":\n",
    "            device_id = get_device_id()\n",
    "            device_num = get_device_num()\n",
    "        else:\n",
    "            raise ValueError(\"Not support device_target.\")\n",
    "\n",
    "        if device_id % min(device_num, 8) == 0 and not os.path.exists(sync_lock):\n",
    "            print(\"Zip file path: \", zip_file_1)\n",
    "            print(\"Unzip file save dir: \", save_dir_1)\n",
    "            unzip(zip_file_1, save_dir_1)\n",
    "            print(\"===Finish extract data synchronization===\")\n",
    "            try:\n",
    "                os.mknod(sync_lock)\n",
    "            except IOError:\n",
    "                pass\n",
    "\n",
    "        while True:\n",
    "            if os.path.exists(sync_lock):\n",
    "                break\n",
    "            time.sleep(1)\n",
    "\n",
    "        print(\"Device: {}, Finish sync unzip data from {} to {}.\".format(device_id, zip_file_1, save_dir_1))\n",
    "\n",
    "    config.ckpt_path = os.path.join(config.output_path, config.ckpt_path)\n",
    "\n",
    "#训练部分\n",
    "@moxing_wrapper(pre_process=modelarts_pre_process)\n",
    "def run_train():\n",
    "    '''run train'''\n",
    "    config.lr_epochs = list(map(int, config.lr_epochs.split(',')))\n",
    "    config.image_size = list(map(int, config.image_size.split(',')))\n",
    "    config.per_batch_size = config.batch_size\n",
    "\n",
    "    _enable_graph_kernel = (config.device_target == \"GPU\")\n",
    "    context.set_context(mode=context.PYNATIVE_MODE,\n",
    "                        enable_graph_kernel=_enable_graph_kernel, device_target=config.device_target)\n",
    "    config.rank = get_rank_id()\n",
    "    config.device_id = get_device_id()\n",
    "    config.group_size = get_device_num()\n",
    "\n",
    "    if config.is_distributed:\n",
    "        if config.device_target == \"Ascend\":\n",
    "            init()\n",
    "            context.set_context(device_id=config.device_id)\n",
    "        elif config.device_target == \"GPU\":\n",
    "            if not config.enable_modelarts:\n",
    "                init()\n",
    "            else:\n",
    "                if not config.need_modelarts_dataset_unzip:\n",
    "                    init()\n",
    "    \n",
    "        device_num = config.group_size\n",
    "        context.reset_auto_parallel_context()\n",
    "        context.set_auto_parallel_context(device_num=device_num, parallel_mode=ParallelMode.DATA_PARALLEL,\n",
    "                                          gradients_mean=True, all_reduce_fusion_config=[15, 18])\n",
    "    \n",
    "    else:\n",
    "        if config.device_target == \"Ascend\":\n",
    "            if context.get_context('device_id')!=config.device_id:\n",
    "                context.set_context(device_id=config.device_id)\n",
    "    \n",
    "    \n",
    "    # select for master rank save ckpt or all rank save, compatible for model parallel\n",
    "    config.rank_save_ckpt_flag = 0\n",
    "    if config.is_save_on_master:\n",
    "        if config.rank == 0:\n",
    "            config.rank_save_ckpt_flag = 1\n",
    "    else:\n",
    "        config.rank_save_ckpt_flag = 1\n",
    "\n",
    "    # logger\n",
    "    config.outputs_dir = os.path.join(config.ckpt_path,\n",
    "                                      datetime.datetime.now().strftime('%Y-%m-%d_time_%H_%M_%S'))\n",
    "    config.logger = get_logger(config.outputs_dir, config.rank)\n",
    "\n",
    "    if config.dataset == \"flower_photos\":\n",
    "        dataset = vgg_create_dataset(config.data_dir, config.image_size, config.per_batch_size,\n",
    "                                     config.rank, config.group_size)\n",
    "        eval_dataset = vgg_create_dataset(config.data_dir, config.image_size, config.per_batch_size,\n",
    "                                     config.rank, config.group_size)\n",
    "\n",
    "    batch_num = dataset.get_dataset_size()\n",
    "    config.steps_per_epoch = dataset.get_dataset_size()\n",
    "    config.logger.save_args(config)\n",
    "\n",
    "    # network\n",
    "    config.logger.important_info('start create network')\n",
    "\n",
    "    # 构建网络\n",
    "    network = vgg17(config.num_classes, config)\n",
    "    network.set_train(True)\n",
    "\n",
    "    # 是否有预训练权重文件\n",
    "    if config.pre_trained:\n",
    "        load_param_into_net(network, load_checkpoint(config.pre_trained))\n",
    "\n",
    "    # 学习率\n",
    "    if config.lr_scheduler == 'exponential':\n",
    "        lr = warmup_step_lr(config.lr,\n",
    "                            config.lr_epochs,\n",
    "                            config.steps_per_epoch,\n",
    "                            config.warmup_epochs,\n",
    "                            config.max_epoch,\n",
    "                            gamma=config.lr_gamma,\n",
    "                            )\n",
    "    elif config.lr_scheduler == 'cosine_annealing':\n",
    "        lr = warmup_cosine_annealing_lr(config.lr,\n",
    "                                        config.steps_per_epoch,\n",
    "                                        config.warmup_epochs,\n",
    "                                        config.max_epoch,\n",
    "                                        config.T_max,\n",
    "                                        config.eta_min)\n",
    "    elif config.lr_scheduler == 'step':\n",
    "        lr = lr_steps(0, lr_init=config.lr_init, lr_max=config.lr_max, warmup_epochs=config.warmup_epochs,\n",
    "                      total_epochs=config.max_epoch, steps_per_epoch=batch_num)\n",
    "    else:\n",
    "        raise NotImplementedError(config.lr_scheduler)\n",
    "\n",
    "    # 优化器\n",
    "    opt = Momentum(params=get_param_groups(network),\n",
    "                   learning_rate=Tensor(lr),\n",
    "                   momentum=config.momentum,\n",
    "                   weight_decay=config.weight_decay,\n",
    "                   loss_scale=config.loss_scale)\n",
    "\n",
    "    \n",
    "    loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "    model = Model(network, loss_fn=loss, optimizer=opt, metrics={\"Accuracy\": Accuracy()},\n",
    "                    amp_level=\"O2\", keep_batchnorm_fp32=False, loss_scale_manager=None)\n",
    "   \n",
    "    # 定义回调函数\n",
    "    time_cb = TimeMonitor(data_size=batch_num)\n",
    "    loss_cb = LossMonitor()\n",
    "    #epoch_per_eval = {\"epoch\": [], \"acc\": []}\n",
    "    #eval_cb = EvalCallBack(model, eval_dataset, 1, epoch_per_eval)  #每个epoch都评估一下\n",
    "    callbacks = [time_cb, loss_cb]\n",
    "    if config.rank_save_ckpt_flag:\n",
    "        ckpt_config = CheckpointConfig(save_checkpoint_steps=config.ckpt_interval * config.steps_per_epoch,\n",
    "                                       keep_checkpoint_max=config.keep_checkpoint_max)\n",
    "        save_ckpt_path = os.path.join(config.outputs_dir, 'ckpt_' + str(config.rank) + '/')\n",
    "        print(save_ckpt_path)\n",
    "        ckpt_cb = ModelCheckpoint(config=ckpt_config,\n",
    "                                  directory=save_ckpt_path,\n",
    "                                  prefix='{}'.format(config.rank))\n",
    "        callbacks.append(ckpt_cb)\n",
    "    \n",
    "    #进行模型训练\n",
    "    model.train(config.max_epoch, dataset, callbacks=callbacks)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c53ec25-47d8-49ed-88fc-3a850a7d1453",
   "metadata": {},
   "source": [
    "### 7. 模型训练与验证"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94142428-13f2-4b34-a614-3b823c17f50e",
   "metadata": {},
   "source": [
    "在Ascend或者GPU上运行，调用run_train()函数，运行结果在train.log中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c679db83-8268-4c1d-8722-6ec026ff0168",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.config_path=\"flowerphotos_config.yaml\"\n",
    "config.dataset=\"flower_photos\"\n",
    "config.is_distributed=0\n",
    "config.data_dir=\"../data\"\n",
    "config.device_target=\"Ascend\" # 或者选GPU\n",
    "config.lr_epochs='30,60,90,120'\n",
    "config.image_size=\"224,224\"\n",
    "config.pre_trained=\"pretrained/0-400_45.ckpt\"\n",
    "\n",
    "run_train()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87237fe1-cf8e-4ba4-a059-47a3c405e86a",
   "metadata": {},
   "source": [
    "使用 mindspore.Model.eval 接口进行评估，相关代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e837646-b8a3-4b35-a148-c305fcc0fec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 Huawei Technologies Co., Ltd\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ============================================================================\n",
    "\"\"\"Eval\"\"\"\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import random \n",
    "import mindspore\n",
    "import glob\n",
    "import numpy as np\n",
    "import mindspore.nn as nn\n",
    "\n",
    "from mindspore import Tensor, context\n",
    "from mindspore.communication import init, get_rank, get_group_size\n",
    "from mindspore.train import Model\n",
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "import mindspore.ops as P\n",
    "from mindspore import dtype as mstype\n",
    "\n",
    "from src.utils.logging import get_logger\n",
    "from src.vgg import vgg17\n",
    "from src.dataset import vgg_create_dataset\n",
    "from src.dataset import classification_dataset\n",
    "\n",
    "from model_utils.moxing_adapter import config\n",
    "from model_utils.moxing_adapter import moxing_wrapper\n",
    "from model_utils.device_adapter import get_device_id, get_rank_id, get_device_num\n",
    "\n",
    "import sys\n",
    "f = open('eval.log', 'w')\n",
    "sys.stdout = f\n",
    "sys.stderr = f \n",
    "\n",
    "class ParameterReduce(nn.Cell):\n",
    "    \"\"\"ParameterReduce\"\"\"\n",
    "    def __init__(self):\n",
    "        super(ParameterReduce, self).__init__()\n",
    "        self.cast = P.Cast()\n",
    "        self.reduce = P.AllReduce()\n",
    "\n",
    "    def construct(self, x):\n",
    "        one = self.cast(P.scalar_to_tensor(1.0), mstype.float32)[0]\n",
    "        out = x * one\n",
    "        ret = self.reduce(out)\n",
    "        return ret\n",
    "\n",
    "\n",
    "def get_top5_acc(top5_arg, gt_class):\n",
    "    sub_count = 0\n",
    "    for top5, gt in zip(top5_arg, gt_class):\n",
    "        if gt in top5:\n",
    "            sub_count += 1\n",
    "    return sub_count\n",
    "\n",
    "\n",
    "def modelarts_pre_process():\n",
    "    '''modelarts pre process function.'''\n",
    "    def unzip(zip_file, save_dir):\n",
    "        import zipfile\n",
    "        s_time = time.time()\n",
    "        if not os.path.exists(os.path.join(save_dir, config.modelarts_dataset_unzip_name)):\n",
    "            zip_isexist = zipfile.is_zipfile(zip_file)\n",
    "            if zip_isexist:\n",
    "                fz = zipfile.ZipFile(zip_file, 'r')\n",
    "                data_num = len(fz.namelist())\n",
    "                print(\"Extract Start...\")\n",
    "                print(\"unzip file num: {}\".format(data_num))\n",
    "                data_print = int(data_num / 100) if data_num > 100 else 1\n",
    "                i = 0\n",
    "                for file in fz.namelist():\n",
    "                    if i % data_print == 0:\n",
    "                        print(\"unzip percent: {}%\".format(int(i * 100 / data_num)), flush=True)\n",
    "                    i += 1\n",
    "                    fz.extract(file, save_dir)\n",
    "                print(\"cost time: {}min:{}s.\".format(int((time.time() - s_time) / 60),\n",
    "                                                     int(int(time.time() - s_time) % 60)))\n",
    "                print(\"Extract Done.\")\n",
    "            else:\n",
    "                print(\"This is not zip.\")\n",
    "        else:\n",
    "            print(\"Zip has been extracted.\")\n",
    "\n",
    "    if config.need_modelarts_dataset_unzip:\n",
    "        zip_file_1 = os.path.join(config.data_path, config.modelarts_dataset_unzip_name + \".zip\")\n",
    "        save_dir_1 = os.path.join(config.data_path)\n",
    "\n",
    "        sync_lock = \"/tmp/unzip_sync.lock\"\n",
    "\n",
    "        # Each server contains 8 devices as most.\n",
    "        if config.device_target == \"GPU\":\n",
    "            init()\n",
    "            device_id = get_rank()\n",
    "            device_num = get_group_size()\n",
    "        elif config.device_target == \"Ascend\":\n",
    "            device_id = get_device_id()\n",
    "            device_num = get_device_num()\n",
    "        else:\n",
    "            raise ValueError(\"Not support device_target.\")\n",
    "\n",
    "        # Each server contains 8 devices as most.\n",
    "        if device_id % min(device_num, 8) == 0 and not os.path.exists(sync_lock):\n",
    "            print(\"Zip file path: \", zip_file_1)\n",
    "            print(\"Unzip file save dir: \", save_dir_1)\n",
    "            unzip(zip_file_1, save_dir_1)\n",
    "            print(\"===Finish extract data synchronization===\")\n",
    "            try:\n",
    "                os.mknod(sync_lock)\n",
    "            except IOError:\n",
    "                pass\n",
    "\n",
    "        while True:\n",
    "            if os.path.exists(sync_lock):\n",
    "                break\n",
    "            time.sleep(1)\n",
    "\n",
    "        print(\"Device: {}, Finish sync unzip data from {} to {}.\".format(device_id, zip_file_1, save_dir_1))\n",
    "\n",
    "    config.log_path = os.path.join(config.output_path, config.log_path)\n",
    "\n",
    "\n",
    "@moxing_wrapper(pre_process=modelarts_pre_process)\n",
    "def run_eval():\n",
    "    \"\"\"run eval\"\"\"\n",
    "    config.per_batch_size = config.batch_size\n",
    "    config.image_size = list(map(int, config.image_size.split(',')))\n",
    "    config.rank = get_rank_id()\n",
    "    config.group_size = get_device_num()\n",
    "\n",
    "\n",
    "    _enable_graph_kernel = config.device_target == \"GPU\"\n",
    "    context.set_context(mode=context.GRAPH_MODE, enable_graph_kernel=False,\n",
    "                        device_target=config.device_target, save_graphs=False)\n",
    "    if os.getenv('DEVICE_ID', \"not_set\").isdigit() and config.device_target == \"Ascend\":\n",
    "        if context.get_context('device_id')!=int(os.getenv('DEVICE_ID')):\n",
    "            context.set_context(device_id=int(os.getenv('DEVICE_ID')))\n",
    "\n",
    "    config.outputs_dir = os.path.join(config.log_path,\n",
    "                                      datetime.datetime.now().strftime('%Y-%m-%d_time_%H_%M_%S'))\n",
    "\n",
    "    config.logger = get_logger(config.outputs_dir, config.rank)\n",
    "    config.logger.save_args(config)\n",
    "\n",
    "    if config.dataset == \"flower_photos\":\n",
    "        net = vgg17(num_classes=config.num_classes, args=config,phase=\"test\")\n",
    "        loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "        model = Model(net, loss_fn=loss, metrics={'acc'})\n",
    "        param_dict = load_checkpoint(config.pre_trained)\n",
    "        load_param_into_net(net, param_dict)\n",
    "        net.set_train(False)\n",
    "        dataset = vgg_create_dataset(config.data_dir, config.image_size, config.per_batch_size, training=False)\n",
    "        res = model.eval(dataset)\n",
    "        print(\"result: \", res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bc0fc5-1c92-4751-be8e-f0ce4504bf44",
   "metadata": {},
   "source": [
    "运行评估代码如下：\n",
    "评估可用output_flowers中生成的权重文件，这里我们用已经生成好的权重文件为例。路径在output文件夹下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd071f71-66d0-47a8-a73a-289e930c9d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.pre_trained=\"output/output_example.ckpt\"\n",
    "config.dataset=\"flower_photos\"\n",
    "config.image_size=\"224,224\"\n",
    "config.device_target=\"Ascend\" # 或者选GPU\n",
    "config.data_dir=\"../data\"\n",
    "\n",
    "run_eval()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
