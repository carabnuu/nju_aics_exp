{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85b67404-50e2-4ff0-a388-86c7fb9a5956",
   "metadata": {},
   "source": [
    "##  TBE算子开发与集成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a801ca-421c-4d58-b214-4b10f1deab99",
   "metadata": {},
   "source": [
    "### 实验目标\n",
    "基于TBE算子开发语言开发运行在AI Core上的自定义算子，并对自定义开发的算子进行性能测试。另\n",
    "外，将自定义开发的算子注册至算子库，在基于算子库构建 VGG16 神经网络时能够运行自定义开发的算\n",
    "子。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad41330-8634-46a0-838a-90ac93cb5009",
   "metadata": {},
   "source": [
    "### 实验内容\n",
    "本实验基于Ascend310实现TBE算子开发，通过调用TBE提供的DSL接口实现BatchNormalization算子\n",
    "和Softmax算子的独立开发及测试，熟悉算子开发流程，进一步了解算子底层实现方式。\n",
    "对于算子开发，首先先对该算子进行算子分析，明确算子的功能及数学表达式，确详细算子规格，例如\n",
    "算子输入输出的数据类型、形态，算子实现的文件名、函数名等，根据已有的 TBE DSL接口判断是否能\n",
    "实现该算子。其次创建项目工程，对于单个算子，需要依次实现算子原型定义、实现算子代码函数、定\n",
    "义算子信息库、实现算子适配插件开发，最后对算子进行编译部署，通过ST（System Test）测试即算\n",
    "完成。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f49dd79-9872-406f-b2fd-058701954bff",
   "metadata": {},
   "source": [
    "### 1. BatchNormalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fe17e7-4e7b-4810-8c47-7da22d7023be",
   "metadata": {},
   "source": [
    "### 算子原型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59852065-3add-41b8-adbd-47e59cfa07f6",
   "metadata": {},
   "source": [
    "算子注册：需要在算子的工程目录的/op_proto/算子名称.h 和 /op_proto/算子名称.cpp 文件中进行实\n",
    "现。\n",
    "在算子工程下的“op_proto/batch_normalization_dsl.h”和“op_proto/batch_normalization_dsl.cc”文件\n",
    "进行实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bbc39f-f9b6-4d86-a9f8-0c7ce81610a0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#ifndef GE_OP_BATCH_NORMALIZATION_DSL_H \\\n",
    "#define GE_OP_BATCH_NORMALIZATION_DSL_H \\\n",
    "#include \"graph/operator_reg.h\" \\\n",
    "\n",
    "namespace ge {\n",
    "\n",
    "REG_OP(BatchNormalizationDSL) \\\n",
    "    .INPUT(x, TensorType({DT_FLOAT,DT_FLOAT16})) \\\n",
    "    .INPUT(scale, TensorType({DT_FLOAT,DT_FLOAT})) \\\n",
    "    .INPUT(offset, TensorType({DT_FLOAT,DT_FLOAT})) \\\n",
    "    .INPUT(mean, TensorType({DT_FLOAT,DT_FLOAT})) \\\n",
    "    .INPUT(variance, TensorType({DT_FLOAT,DT_FLOAT})) \\\n",
    "    .OUTPUT(y, TensorType({DT_FLOAT,DT_FLOAT16})) \\\n",
    "    .OUTPUT(batch_mean, TensorType({DT_FLOAT,DT_FLOAT})) \\\n",
    "    .OUTPUT(batch_variance, TensorType({DT_FLOAT,DT_FLOAT})) \\\n",
    "    .REQUIRED_ATTR(epsilon, Float) \\\n",
    "    .REQUIRED_ATTR(is_training, Bool) \\\n",
    "    .OP_END_FACTORY_REG(BatchNormalizationDSL) \\\n",
    "}\n",
    "\n",
    "#endif //GE_OP_BATCH_NORMALIZATION_DSL_H\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c528d687-041e-4b26-9d3f-03cd6e19c28d",
   "metadata": {},
   "source": [
    "### 算子函数实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfa4c4d-1645-4c1b-9d3f-2e8651e2e437",
   "metadata": {},
   "source": [
    "通过调用TBE DSL接口，在算子工程下的“tbe/impl/batch_normalization_dsl.py”文件中进行\n",
    "BatchNormalizationDSL算子的实现，主要包括算子函数定义、算子入参校验、compute过程实现及调\n",
    "度与编译。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "532a0603-370f-4546-8401-f107ab9ad551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tbe import tvm\n",
    "from tbe.common.register import register_op_compute\n",
    "import te.lang.cce as tbe\n",
    "import te.platform as tbe_platform\n",
    "from te.utils import para_check\n",
    "from te.utils import shape_util\n",
    "\n",
    "\n",
    "def _output_data_y_compute(x, mean, variance, scale, offset, epsilon):\n",
    "    # x = (x - mean)/(var + epsilon)**0.5\n",
    "    # y = scale*x + offset\n",
    "    shape_x = shape_util.shape_to_list(x.shape)\n",
    "    y_add = tbe.vadds(variance, epsilon)\n",
    "    y_sqrt = tbe.vsqrt(y_add)\n",
    "    var_sub = tbe.vsub(x, mean)\n",
    "    y_norm = tbe.vdiv(var_sub, y_sqrt)\n",
    "    scale_broad = tbe.broadcast(scale, shape_x)\n",
    "    offset_broad = tbe.broadcast(offset, shape_x)\n",
    "    res = tbe.vadd(tbe.vmul(scale_broad, y_norm), offset_broad)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def _batch_norm_dsl_train_compute(x, scale, offset, epsilon):\n",
    "    # 如果输入x的dtype为float16，则转为float32进行计算, 防止训练的时候下溢造成训练困难\n",
    "    is_cast = False\n",
    "    if x.dtype == \"float16\" and tbe_platform.cce_conf.api_check_support(\"te.lang.cce.vdiv\", \"float32\"):\n",
    "        is_cast = True\n",
    "        x = tbe.cast_to(x, \"float32\")\n",
    "\n",
    "    shape_x = shape_util.shape_to_list(x.shape)\n",
    "\n",
    "    axis = [0, 2, 3]    # NHW\n",
    "    num = shape_x[0]*shape_x[2]*shape_x[3]\n",
    "    num_rec = 1.0/num\n",
    "\n",
    "    # 根据 x 的维度 C 计算均值\n",
    "    mean_sum = tbe.sum(x, axis, True)\n",
    "    mean_muls = tbe.vmuls(mean_sum, num_rec)\n",
    "    mean_broadcast = tbe.broadcast(mean_muls, shape_x)\n",
    "\n",
    "    # 根据 x 的维度 C 计算方差\n",
    "    var_sub = tbe.vsub(x, mean_broadcast)\n",
    "    var_mul = tbe.vmul(var_sub, var_sub)\n",
    "    var_sum = tbe.sum(var_mul, axis, True)\n",
    "    var_muls = tbe.vmuls(var_sum, num_rec)\n",
    "    var_broadcast = tbe.broadcast(var_muls, shape_x)\n",
    "\n",
    "    # BatchNormalization 计算\n",
    "    res_y = _output_data_y_compute(x, mean_broadcast, var_broadcast, scale, offset, epsilon)\n",
    "\n",
    "    # 保持输入输出的dtype一致\n",
    "    if is_cast:\n",
    "        res_y = tbe.cast_to(res_y, \"float16\")\n",
    "\n",
    "    # 计算当前batch的均值和方差 NCHW -> C\n",
    "    res_batch_mean = tbe.vmuls(mean_sum, num_rec)\n",
    "    if num == 1:\n",
    "        batch_var_scaler = 0.0\n",
    "    else:\n",
    "        batch_var_scaler = float(num)/(num - 1)\n",
    "    res_batch_var = tbe.vmuls(var_muls, batch_var_scaler)\n",
    "    res = [res_y, res_batch_mean, res_batch_var]\n",
    "    return res\n",
    "\n",
    "\n",
    "def _batch_norm_dsl_inf_compute(x, scale, offset, mean, variance, epsilon):\n",
    "    # 如果输入x的dtype为float16，则转为float32进行计算\n",
    "    is_cast = False\n",
    "    if x.dtype == \"float16\" and tbe_platform.cce_conf.api_check_support(\"te.lang.cce.vdiv\", \"float32\"):\n",
    "        is_cast = True\n",
    "        x = tbe.cast_to(x, \"float32\")\n",
    "    shape_x = shape_util.shape_to_list(x.shape)\n",
    "\n",
    "    # 将已有的均值和方差广播至同纬度\n",
    "    mean_broadcast = tbe.broadcast(mean, shape_x)\n",
    "    var_broadcast = tbe.broadcast(variance, shape_x)\n",
    "\n",
    "    # BatchNormalization 计算\n",
    "    res_y = _output_data_y_compute(x, mean_broadcast, var_broadcast, scale, offset, epsilon)\n",
    "\n",
    "    # 保持输入输出的dtype一致\n",
    "    if is_cast:\n",
    "        res_y = tbe.cast_to(res_y, \"float16\")\n",
    "\n",
    "    # 推理的batch_mean和batch_var 即为传入的mean和variance\n",
    "    scaler_zero = 0.0\n",
    "    res_batch_mean = tbe.vadds(mean, scaler_zero)\n",
    "    res_batch_var = tbe.vadds(variance, scaler_zero)\n",
    "    res = [res_y, res_batch_mean, res_batch_var]\n",
    "    return res\n",
    "\n",
    "\n",
    "@register_op_compute(\"batch_normalization_dsl\")\n",
    "def batch_normalization_dsl_compute(x, scale, offset, mean, variance, y, batch_mean, batch_variance, epsilon, is_training, kernel_name=\"batch_normalization_dsl\"):\n",
    "    if is_training:     # 训练时，均值和方差根据样本计算得到\n",
    "        res = _batch_norm_dsl_train_compute(x, scale, offset, epsilon)\n",
    "    else:               # 推理时，均值和方差需要传入\n",
    "        res = _batch_norm_dsl_inf_compute(x, scale, offset, mean, variance, epsilon)\n",
    "    return res\n",
    "\n",
    "\n",
    "@para_check.check_op_params(para_check.REQUIRED_INPUT, para_check.REQUIRED_INPUT, para_check.REQUIRED_INPUT, para_check.OPTION_INPUT, para_check.OPTION_INPUT, para_check.REQUIRED_OUTPUT, para_check.REQUIRED_OUTPUT, para_check.REQUIRED_OUTPUT, para_check.OPTION_ATTR_FLOAT, para_check.REQUIRED_ATTR_BOOL, para_check.KERNEL_NAME)\n",
    "def batch_normalization_dsl(x, scale, offset, mean, variance, y, batch_mean, batch_variance, epsilon, is_training, kernel_name=\"batch_normalization_dsl\"):\n",
    "    \"\"\"\n",
    "    x: 输入张量(N,C1,H,W,C0)\n",
    "    scale: 缩放量(C1*C0,)\n",
    "    offset: 偏移量(C1*C0,)\n",
    "    mean: 均值(C1*C0,)\n",
    "    variance: 方差(C1*C0,)\n",
    "    y: 输出张量(N,C1,H,W,C0)\n",
    "    batch_mean: 当前张量的均值(C1*C0,)\n",
    "    batch_variance: 当前张量的方差(C1*C0,)\n",
    "    epsilon: 防止方差为0导致除数为0\n",
    "    is_training: 训练验证开关\n",
    "    kernel_name: 算子名称\n",
    "    \"\"\"\n",
    "    # 检查输入的dtype和shape\n",
    "    shape_x = x.get(\"shape\")\n",
    "    dtype_x = x.get(\"dtype\")\n",
    "    para_check.check_shape(shape_x, param_name=\"x\")\n",
    "    para_check.check_dtype(dtype_x.lower(), (\"float16\", \"float32\"), param_name=\"x\")\n",
    "\n",
    "    dtype_scale = scale.get(\"dtype\")\n",
    "    dtype_offset = offset.get(\"dtype\")\n",
    "    para_check.check_dtype(dtype_scale.lower(), (\"float32\", \"float16\"), param_name=\"scale\")\n",
    "    para_check.check_dtype(dtype_offset.lower(), (\"float32\", \"float16\"), param_name=\"offset\")\n",
    "    if not is_training:\n",
    "        dtype_mean = mean.get(\"dtype\")\n",
    "        dtype_variance = variance.get(\"dtype\")\n",
    "        para_check.check_dtype(dtype_mean.lower(), (\"float32\", \"float16\"), param_name=\"mean\")\n",
    "        para_check.check_dtype(dtype_variance.lower(), (\"float32\", \"float16\"), param_name=\"variance\")\n",
    "\n",
    "    # (C1*C0,) -> (1,C1,1,1,C0)\n",
    "    shape_scale = [1, shape_x[1], 1, 1, shape_x[4]]\n",
    "    shape_offset = shape_scale\n",
    "    if not is_training:\n",
    "        shape_mean = shape_scale\n",
    "        shape_variance = shape_scale\n",
    "\n",
    "    # 构建输入节点, 使用TVM的placeholder接口对输入tensor进行占位，返回tensor对象\n",
    "    data_x = tvm.placeholder(shape_x, dtype=dtype_x.lower(), name=\"data_x\")\n",
    "    data_scale = tvm.placeholder(shape_scale, dtype=dtype_scale.lower(), name=\"data_scale\")\n",
    "    data_offset = tvm.placeholder(shape_offset, dtype=dtype_offset.lower(), name=\"data_offset\")\n",
    "    if is_training:\n",
    "        data_mean, data_variance = None, None\n",
    "    else:\n",
    "        data_mean = tvm.placeholder(shape_mean, dtype=dtype_mean, name=\"data_mean\")\n",
    "        data_variance = tvm.placeholder(shape_variance, dtype=dtype_variance, name=\"data_variance\")\n",
    "\n",
    "    # BatchNormalization计算\n",
    "    res = batch_normalization_dsl_compute(data_x, data_scale, data_offset, \n",
    "                                          data_mean, data_variance, y, \n",
    "                                          batch_mean, batch_variance, epsilon, \n",
    "                                          is_training, kernel_name)\n",
    "\n",
    "    # 自动调度\n",
    "    with tvm.target.cce():\n",
    "        schedule = tbe.auto_schedule(res)\n",
    "\n",
    "    if is_training:\n",
    "        tensor_list = [data_x, data_scale, data_offset] + list(res)\n",
    "    else:\n",
    "        tensor_list = [data_x, data_scale, data_offset,\n",
    "                       data_mean, data_variance] + list(res)\n",
    "\n",
    "    # 编译配置\n",
    "    config = {\"name\": kernel_name,\n",
    "              \"tensor_list\": tensor_list}\n",
    "    tbe.build(schedule, config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994419a3-ea4f-4f88-ba64-1ab3076fd6f4",
   "metadata": {},
   "source": [
    "### 配置算子信息库\n",
    "算子信息库的路径为“tbe/op_info_cfg/ai_core/ascend310/batch_normalization_dsl.ini”，包含了算子\n",
    "的类型，输入输出的名称、数据类型、数据排布格式等信息，msopgen工具已经根据\n",
    "batch_normalization_dsl.json文件将上述内容自动填充，开发者无需修改。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8dce59-1e99-4a75-8014-10b71d580687",
   "metadata": {},
   "source": [
    "### 实验运行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28a7208-b6d8-4dcb-804a-a1f062cb8a2e",
   "metadata": {},
   "source": [
    "    # 激活环境\n",
    "    ! source /usr/local/Ascend/ascend-toolkit/set_env.sh\n",
    "    # 1.工程创建\n",
    "    ! /usr/local/Ascend/ascend-toolkit/latest/python/site-packages/bin/msopgen gen -i /root/EXP/exp6/batch_normalization_dsl.json -f tf -c ai_core-Ascend310 -out /root/EXP/exp6/BatchNormalizationDSL \n",
    "    # 切换工程目录 \n",
    "    ! cd BatchNormalizationDS\n",
    "\n",
    "    # 2.算子开发 \n",
    "    # 2.1 定义算子原型文件 \n",
    "    vim op_proto/batch_normalization_dsl.cc \n",
    "\n",
    "    # 2.2 算子函数实现 \n",
    "    vim tbe/impl/batch_normalization_dsl.py \n",
    "\n",
    "    # 3.算子编译部署 \n",
    "\n",
    "    chmod 775 build.sh vim build.sh \n",
    "    # 配置算子编译所需环境变量 \n",
    "    ./build.sh \n",
    "\n",
    "\n",
    "    # 编译 \n",
    "    ./build_out/custom_opp_ubuntu_x86_64.run \n",
    "\n",
    "\n",
    "    # 部署 \n",
    "    # 切换工程目录 \n",
    "    cd .. \n",
    "\n",
    "\n",
    "    # 设置环境变量 \n",
    "    source env_npu.sh \n",
    "\n",
    "\n",
    "    # 4.测试 \n",
    "    # 推理测试用例 \n",
    "    /usr/local/Ascend/ascend-toolkit/latest/python/site-packages/bin/msopst run -i /root/EXP/exp6/test_batch_normalization_dsl.json -soc Ascend310 -out /root/EXP/exp6/out \n",
    "    # 训练测试用例 \n",
    "    /usr/local/Ascend/ascend-toolkit/latest/python/site-packages/bin/msopst run -i /root/EXP/exp6/test_batch_normalization_dsl2.json -soc Ascend310 -out /root/EXP/exp6/out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfce63a-29a6-457b-a374-f1549f0ac582",
   "metadata": {},
   "source": [
    "### 2. Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dc5d04-5e54-4137-8394-41e99fd95928",
   "metadata": {},
   "source": [
    "### 算子原型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b95801a-27a2-4138-b201-6d4809750082",
   "metadata": {},
   "source": [
    " 算子原型定义了算子的数学含义：包含算子的输入、输出、属性信息；算子参数的校验和shape的推\n",
    "导。定义好的算子被注册到算子原型库中。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b7e1e8-f15e-413e-8fda-80121bbf03f8",
   "metadata": {},
   "source": [
    "\n",
    "#ifndef GE_OP_SOFTMAX_H \\\n",
    "#define GE_OP_SOFTMAX_H \\\n",
    "#include \"graph/operator_reg.h\"\n",
    "\n",
    "namespace ge {\n",
    "\n",
    "REG_OP(Softmax) \\\n",
    "    .INPUT(x, TensorType({DT_FLOAT,DT_FLOAT16})) \\\n",
    "    .OUTPUT(y, TensorType({DT_FLOAT,DT_FLOAT16})) \\\n",
    "    .ATTR(axis, ListInt, {-1}) \\\n",
    "    .OP_END_FACTORY_REG(Softmax) \\\n",
    "}\n",
    "\n",
    "#endif //GE_OP_SOFTMAX_H\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3669d09-124c-4c1c-8292-e0f147be19fa",
   "metadata": {},
   "source": [
    "### 算子函数实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97745b50-eba4-430f-87a4-1c828115506b",
   "metadata": {},
   "source": [
    "通过调用TBE DSL接口，在算子工程下的“tbe/impl/softmax.py”文件中进行softmax算子的实现，主要\n",
    "包括算子函数定义、算子入参校验、compute过程实现及调度与编译"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d4c33e8-49e7-4f41-aaf0-2bb1b98a7e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "softmax\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "import tbe\n",
    "from te.utils import shape_util\n",
    "import te.tvm as tvm\n",
    "import te.lang.cce\n",
    "import te.platform as tbe_platform\n",
    "from te.utils import para_check     # 提供了通用的算子参数校验接口\n",
    "from te.utils import shape_util\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 其作用是整网运行时，支持算子做UB自动融合，使得算子在UB中根据UB融合规则自动与其他算子的compute进行拼接，提升算子运行效率,，若算子实现逻辑中涉及reshape操作，不可使用此装饰器函数\n",
    "@tbe.common.register.register_op_compute(\"Softmax\")\n",
    "def softmax_compute(input_x, output_y, axis=-1, kernel_name=\"softmax\"):\n",
    "    \"\"\"\n",
    "    softmax:\n",
    "        input_x: 算子的输入tensor，每个tensor需要采用字典的形式进行定义，包含shape、ori_shape、format、ori_format与dtype信息，用于计算Softmax函数的Tensor，数据类型为float16或float32。\n",
    "        output_y: 算子的输出tensor，包含shape和dtype等信息，字典格式，数据类型和shape与 x 相同，取值范围为[0, 1]。\n",
    "        axis: 指定Softmax运算的轴axis，假设输入 x 的维度为x.ndim，则axis的范围为 [-x.ndim, x.ndim) ，-1表示最后一个维度。默认值：-1。\n",
    "        kernel_name: 算子在内核中的名称\n",
    "    \"\"\"\n",
    "    dtype = input_x.dtype.lower()\n",
    "    shape = input_x.shape\n",
    "    has_improve_precision = False\n",
    "\n",
    "\n",
    "    # 分子 e^x\n",
    "    data_exp = te.lang.cce.vexp(input_x)\n",
    "\n",
    "    # 对于输入数据类型为float16的来说，可以先广播到float32，做以下的除法操作，再转为数据类型float16，用于提升计算精度\n",
    "    tbe_product = tbe_platform.cce_conf.get_soc_spec(\"SOC_VERSION\")\n",
    "    if data_exp.dtype == \"float16\" and tbe_product in (\"Ascend310\",):\n",
    "        data_exp = te.lang.cce.cast_to(data_exp, \"float32\")\n",
    "        has_improve_precision = True\n",
    "\n",
    "    # sum(e^x) 分母，将分母也广播到shape大小\n",
    "    data_expsum = te.lang.cce.sum(data_exp, axis, keepdims=True)\n",
    "    data_expsum = te.lang.cce.broadcast(data_expsum, shape)\n",
    "\n",
    "    # e^x/sum(e^x)\n",
    "    output = te.lang.cce.vdiv(data_exp, data_expsum)\n",
    "\n",
    "    #转为数据类型为float16\n",
    "    if has_improve_precision and dtype == \"float16\":\n",
    "        output = te.lang.cce.cast_to(output, \"float16\")\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "# 对算子的输入、输出、属性及Kernel Name进行基础校验\n",
    "@para_check.check_op_params(para_check.REQUIRED_INPUT, para_check.REQUIRED_OUTPUT,\n",
    "                            (para_check.OPTION_ATTR_INT, para_check.OPTION_ATTR_LIST_INT), para_check.KERNEL_NAME,\n",
    "                            para_check.OPTION_ATTR_STR)\n",
    "def softmax(input_x, output_y, axis=-1, kernel_name=\"softmax\"):\n",
    "    \"\"\"\n",
    "    softmax:\n",
    "    ----------\n",
    "    input_x : dict\n",
    "    format: ND\n",
    "    dtype:  float16, float32\n",
    "    output_y: dict，shape和dtype应该和input_x一样\n",
    "    axis : Intlist\n",
    "    kernel_name : str，这里为softmax\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # 获取算子输入tensor的shape以及dtype，为后续定义输入tensor的张量占位符做准备。\n",
    "    shape = input_x.get(\"shape\")\n",
    "    dtype = input_x.get(\"dtype\").lower()\n",
    "    axis=list(axis)\n",
    "\n",
    "    # 基本校验\n",
    "    para_check.check_shape(shape, param_name=\"x\")\n",
    "    para_check.check_dtype(dtype.lower(), (\"float16\", \"float32\"), param_name=\"x\")\n",
    "\n",
    "    axis = shape_util.axis_check(len(shape), axis)  # 对轴的值进行合法性校验，并返回排好序且是正数的轴值，轴值按照升序进行排序\n",
    "\n",
    "    shape, axis = shape_util.shape_refine(list(shape), axis)  # recude dim=1 的轴\n",
    "    shape, axis = shape_util.simplify_axis_shape(shape, axis) # 把连续的reduce轴进行合并，并把对应的shape的维度也进行合并\n",
    "\n",
    "    data_x = tvm.placeholder(shape, dtype=dtype, name=\"data_x\")\n",
    "\n",
    "    with tvm.target.cce():\n",
    "        output = softmax_compute(data_x, output_y, axis, kernel_name)\n",
    "        result = tbe.dsl.auto_schedule(output)  # 调用auto_schedule接口，便可以自动生成算子相应的调度\n",
    "\n",
    "    tensor_list = [data_x, output]\n",
    "    # TVM的打印机制；可以看到相应计算的中间表示。配置信息包括是否需要打印IR、是否编译以及算子内核名以及输入、输出张量\n",
    "    config = {\"name\": kernel_name,\n",
    "                \"tensor_list\": tensor_list}\n",
    "\n",
    "    tbe.dsl.build(result, config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88498fa4-0a0c-4774-a76c-fc6fc4a4323d",
   "metadata": {},
   "source": [
    "算子信息库的路径为“tbe/op_info_cfg/ai_core/ascend310/softmax.ini”，包含了算子的类型，输入输出\n",
    "的名称、数据类型、数据排布格式等信息，msopgen工具已经根据softmax.json文件将上述内容自动填充，开发者无需修改。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdeabf5-a72f-484f-8906-3699360ec604",
   "metadata": {},
   "source": [
    "### 实验运行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334e898d-ecb8-485b-98b9-bbc81e1e88b7",
   "metadata": {},
   "source": [
    "    # TODO 学生需要按照指令操作的部分 \n",
    "    # 请按照以下指令和上述操作过程，顺利完成算子开发 \n",
    "    # 1.激活环境 \n",
    "    source /usr/local/Ascend/ascend-toolkit/set_env.sh \n",
    "\n",
    "    # 切换工程目录 \n",
    "    cd Softmax \n",
    "\n",
    "    # 2.算子开发 \n",
    "    # 2.1 定义算子原型文件 \n",
    "    vim op_proto/softmax.cc \n",
    "\n",
    "    # 2.2 算子函数实现 \n",
    "    vim tbe/impl/softmax.py \n",
    "\n",
    "    # 3.算子编译部署 \n",
    "    chmod 775 build.sh vim build.sh \n",
    "\n",
    "    # 配置算子编译所需环境变量 \n",
    "    ./build.sh \n",
    "\n",
    "    # 编译 \n",
    "    ./build_out/custom_opp_ubuntu_x86_64.run \n",
    "\n",
    "    # 部署 \n",
    "    # 切换工程目录 \n",
    "    cd .. \n",
    "\n",
    "    # 设置环境变量 \n",
    "    source env_npu.sh \n",
    "\n",
    "    # 4.测试 \n",
    "    # 推理测试用例 \n",
    "    /usr/local/Ascend/ascend-toolkit/latest/python/site-packages/bin/msopst run -i ./test_softmax_case.json -soc Ascend310 -out ./out\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
